#!/usr/bin/env python3
"""
è¨ˆç®—åŒ–å­¦ãƒ»æ©Ÿæ¢°å­¦ç¿’ç ”ç©¶ç’°å¢ƒ åˆæœŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç’°å¢ƒã®å‹•ä½œç¢ºèªã¨åˆæœŸè¨­å®šã‚’è¡Œã„ã¾ã™
"""

import os
import sys
import json
import subprocess
import importlib
from pathlib import Path
from typing import Dict, List, Tuple

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›ç”¨
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    RESET = '\033[0m'

def print_colored(message: str, color: str = Colors.WHITE):
    """è‰²ä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›"""
    print(f"{color}{message}{Colors.RESET}")

def print_header(title: str):
    """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å‡ºåŠ›"""
    print()
    print_colored("=" * 60, Colors.CYAN)
    print_colored(f"  {title}", Colors.CYAN)
    print_colored("=" * 60, Colors.CYAN)
    print()

def check_gpu() -> bool:
    """GPUç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯"""
    print_header("ğŸ® GPUç’°å¢ƒãƒã‚§ãƒƒã‚¯")
    
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        
        if cuda_available:
            device_count = torch.cuda.device_count()
            device_name = torch.cuda.get_device_name(0)
            memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            
            print_colored(f"âœ… CUDAåˆ©ç”¨å¯èƒ½", Colors.GREEN)
            print(f"  - ãƒ‡ãƒã‚¤ã‚¹æ•°: {device_count}")
            print(f"  - GPUå: {device_name}")
            print(f"  - ãƒ¡ãƒ¢ãƒª: {memory:.1f} GB")
            
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
            test_tensor = torch.randn(1000, 1000).cuda()
            result = torch.mm(test_tensor, test_tensor)
            print_colored("âœ… GPUæ¼”ç®—ãƒ†ã‚¹ãƒˆæˆåŠŸ", Colors.GREEN)
            
            return True
        else:
            print_colored("âš ï¸ CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", Colors.YELLOW)
            return False
            
    except ImportError:
        print_colored("âŒ PyTorchãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“", Colors.RED)
        return False
    except Exception as e:
        print_colored(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", Colors.RED)
        return False

def check_libraries() -> Dict[str, bool]:
    """å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯"""
    print_header("ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯")
    
    libraries = {
        # è¨ˆç®—åŒ–å­¦
        "rdkit": "RDKit (ã‚±ãƒ¢ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹)",
        "ase": "ASE (åŸå­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)",
        "MDAnalysis": "MDAnalysis (åˆ†å­å‹•åŠ›å­¦)",
        "pyscf": "PySCF (é‡å­åŒ–å­¦)",
        
        # æ©Ÿæ¢°å­¦ç¿’
        "torch": "PyTorch",
        "tensorflow": "TensorFlow",
        "sklearn": "scikit-learn",
        "xgboost": "XGBoost",
        "transformers": "Transformers",
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹
        "numpy": "NumPy",
        "scipy": "SciPy",
        "pandas": "Pandas",
        "matplotlib": "Matplotlib",
        "jupyter": "Jupyter",
    }
    
    results = {}
    
    for lib, name in libraries.items():
        try:
            importlib.import_module(lib)
            print_colored(f"âœ… {name}: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿", Colors.GREEN)
            results[lib] = True
        except ImportError:
            print_colored(f"âŒ {name}: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«", Colors.RED)
            results[lib] = False
    
    # ã‚µãƒãƒªãƒ¼
    installed = sum(results.values())
    total = len(results)
    
    print()
    if installed == total:
        print_colored(f"ğŸ‰ ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨å¯èƒ½ã§ã™ ({installed}/{total})", Colors.GREEN)
    else:
        print_colored(f"âš ï¸ ä¸€éƒ¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({installed}/{total})", Colors.YELLOW)
    
    return results

def check_ollama() -> bool:
    """Ollamaã®æ¥ç¶šã‚’ãƒã‚§ãƒƒã‚¯"""
    print_header("ğŸ¤– Ollamaæ¥ç¶šãƒã‚§ãƒƒã‚¯")
    
    try:
        import requests
        
        # Ollamaã‚µãƒ¼ãƒãƒ¼ã®ç¢ºèª
        response = requests.get("http://host.docker.internal:11434/api/tags", timeout=5)
        
        if response.status_code == 200:
            models = response.json().get("models", [])
            print_colored("âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šæˆåŠŸ", Colors.GREEN)
            
            if models:
                print("  åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
                for model in models:
                    name = model.get("name", "unknown")
                    size = model.get("size", 0) / 1e9
                    print(f"    - {name} ({size:.1f} GB)")
            else:
                print_colored("  âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“", Colors.YELLOW)
            
            return True
        else:
            print_colored("âŒ Ollamaã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«å¤±æ•—", Colors.RED)
            return False
            
    except requests.exceptions.ConnectionError:
        print_colored("âŒ Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“", Colors.RED)
        print("  ãƒ›ã‚¹ãƒˆå´ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print("    ollama serve")
        return False
    except Exception as e:
        print_colored(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", Colors.RED)
        return False

def check_services() -> Dict[str, bool]:
    """å„ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
    print_header("ğŸ”§ ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯")
    
    services = {
        "http://localhost:8888": "JupyterLab",
        "http://localhost:8080": "Claude-bridge",
        "http://localhost:9121": "Serena-MCP",
        "http://localhost:9122": "Serena Dashboard",
    }
    
    results = {}
    
    try:
        import requests
        
        for url, name in services.items():
            try:
                response = requests.get(url, timeout=3)
                if response.status_code < 500:
                    print_colored(f"âœ… {name}: ç¨¼åƒä¸­ ({url})", Colors.GREEN)
                    results[name] = True
                else:
                    print_colored(f"âš ï¸ {name}: ã‚¨ãƒ©ãƒ¼å¿œç­” ({url})", Colors.YELLOW)
                    results[name] = False
            except:
                print_colored(f"âŒ {name}: æ¥ç¶šä¸å¯ ({url})", Colors.RED)
                results[name] = False
                
    except ImportError:
        print_colored("âŒ requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™", Colors.RED)
        
    return results

def create_sample_notebook():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
    print_header("ğŸ““ ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ä½œæˆ")
    
    notebook_content = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "# è¨ˆç®—åŒ–å­¦ãƒ»æ©Ÿæ¢°å­¦ç¿’ç ”ç©¶ç’°å¢ƒ ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\\n",
                    "\\n",
                    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ç’°å¢ƒã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ç¤ºã—ã¾ã™ã€‚"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\\n",
                    "import numpy as np\\n",
                    "import pandas as pd\\n",
                    "import matplotlib.pyplot as plt\\n",
                    "from rdkit import Chem\\n",
                    "from rdkit.Chem import Descriptors\\n",
                    "import torch\\n",
                    "\\n",
                    "print('ç’°å¢ƒã®æº–å‚™å®Œäº†ï¼')"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 1. RDKitã‚’ä½¿ã£ãŸåˆ†å­æ“ä½œ"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# ã‚¢ã‚¹ãƒ”ãƒªãƒ³ã®åˆ†å­ã‚’ä½œæˆ\\n",
                    "aspirin = Chem.MolFromSmiles('CC(=O)OC1=CC=CC=C1C(=O)O')\\n",
                    "\\n",
                    "# åˆ†å­ç‰¹æ€§ã®è¨ˆç®—\\n",
                    "mw = Descriptors.MolWt(aspirin)\\n",
                    "logp = Descriptors.MolLogP(aspirin)\\n",
                    "hbd = Descriptors.NumHDonors(aspirin)\\n",
                    "hba = Descriptors.NumHAcceptors(aspirin)\\n",
                    "\\n",
                    "print(f'åˆ†å­é‡: {mw:.2f}')\\n",
                    "print(f'LogP: {logp:.2f}')\\n",
                    "print(f'æ°´ç´ çµåˆãƒ‰ãƒŠãƒ¼: {hbd}')\\n",
                    "print(f'æ°´ç´ çµåˆã‚¢ã‚¯ã‚»ãƒ—ã‚¿ãƒ¼: {hba}')"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 2. PyTorchã§ã®ç°¡å˜ãªæ©Ÿæ¢°å­¦ç¿’"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# GPUã®ç¢ºèª\\n",
                    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n",
                    "print(f'ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}')\\n",
                    "\\n",
                    "# ç°¡å˜ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\\n",
                    "class SimpleNet(torch.nn.Module):\\n",
                    "    def __init__(self):\\n",
                    "        super().__init__()\\n",
                    "        self.fc1 = torch.nn.Linear(10, 50)\\n",
                    "        self.fc2 = torch.nn.Linear(50, 1)\\n",
                    "    \\n",
                    "    def forward(self, x):\\n",
                    "        x = torch.relu(self.fc1(x))\\n",
                    "        return self.fc2(x)\\n",
                    "\\n",
                    "model = SimpleNet().to(device)\\n",
                    "print(f'ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}')"
                ]
            }
        ],
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "name": "python",
                "version": "3.12.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 5
    }
    
    # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä¿å­˜
    notebook_path = Path("/workspace/notebooks/sample_notebook.ipynb")
    notebook_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(notebook_path, "w") as f:
        json.dump(notebook_content, f, indent=2)
    
    print_colored(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ: {notebook_path}", Colors.GREEN)

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print_colored("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   è¨ˆç®—åŒ–å­¦ãƒ»æ©Ÿæ¢°å­¦ç¿’ç ”ç©¶ç’°å¢ƒ åˆæœŸåŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ           â•‘
    â•‘   Computational Chemistry & ML Research Environment     â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """, Colors.MAGENTA)
    
    # å„ç¨®ãƒã‚§ãƒƒã‚¯
    gpu_ok = check_gpu()
    libraries = check_libraries()
    ollama_ok = check_ollama()
    services = check_services()
    
    # ã‚µãƒ³ãƒ—ãƒ«ä½œæˆ
    try:
        create_sample_notebook()
    except Exception as e:
        print_colored(f"ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ä½œæˆã«å¤±æ•—: {e}", Colors.YELLOW)
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print_header("ğŸ“‹ ç’°å¢ƒè¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ")
    
    all_ok = True
    
    if gpu_ok:
        print_colored("âœ… GPU: æ­£å¸¸", Colors.GREEN)
    else:
        print_colored("âš ï¸ GPU: å•é¡Œã‚ã‚Š", Colors.YELLOW)
        all_ok = False
    
    if all(libraries.values()):
        print_colored("âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ã™ã¹ã¦åˆ©ç”¨å¯èƒ½", Colors.GREEN)
    else:
        missing = [k for k, v in libraries.items() if not v]
        print_colored(f"âš ï¸ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: {len(missing)}å€‹ä¸è¶³", Colors.YELLOW)
        all_ok = False
    
    if ollama_ok:
        print_colored("âœ… Ollama: æ¥ç¶šæˆåŠŸ", Colors.GREEN)
    else:
        print_colored("âš ï¸ Ollama: æ¥ç¶šå¤±æ•—", Colors.YELLOW)
        all_ok = False
    
    if all(services.values()):
        print_colored("âœ… ã‚µãƒ¼ãƒ“ã‚¹: ã™ã¹ã¦ç¨¼åƒä¸­", Colors.GREEN)
    else:
        print_colored("âš ï¸ ã‚µãƒ¼ãƒ“ã‚¹: ä¸€éƒ¨åœæ­¢ä¸­", Colors.YELLOW)
        all_ok = False
    
    print()
    if all_ok:
        print_colored("ğŸ‰ ç’°å¢ƒã¯å®Œå…¨ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼", Colors.GREEN)
        print_colored("   JupyterLabã«ã‚¢ã‚¯ã‚»ã‚¹: http://localhost:8888", Colors.CYAN)
        print_colored("   Token: research2025", Colors.CYAN)
    else:
        print_colored("âš ï¸ ä¸€éƒ¨ã®æ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", Colors.YELLOW)
    
    print()
    print_colored("Happy Research! ğŸ§ªğŸ¤–ğŸ’»", Colors.MAGENTA)

if __name__ == "__main__":
    main()