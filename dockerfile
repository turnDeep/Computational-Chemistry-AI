# ================================================
# RTX 50ã‚·ãƒªãƒ¼ã‚ºï¼ˆBlackwell sm_120ï¼‰å¯¾å¿œç‰ˆ
# CUDA 12.8 + PyTorch Nightlyãƒ“ãƒ«ãƒ‰ã‚’ä½¿ç”¨
# ================================================

# CUDA 12.8 Ubuntu 24.04 ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆBlackwellå¯¾å¿œï¼‰
FROM nvidia/cuda:12.8.0-cudnn-devel-ubuntu24.04

# ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆsm_120å¯¾å¿œï¼‰
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    CUDA_HOME=/usr/local/cuda-12.8 \
    PATH=/usr/local/cuda-12.8/bin:$PATH \
    LD_LIBRARY_PATH=/usr/local/cuda-12.8/lib64:$LD_LIBRARY_PATH \
    OLLAMA_HOST=http://host.docker.internal:11434 \
    OLLAMA_MODEL=gpt-oss-20b \
    CLAUDE_BRIDGE_PORT=8080 \
    MCP_SERVER_PORT=9121 \
    LANG=en_US.UTF-8 \
    LC_ALL=en_US.UTF-8 \
    TORCH_CUDA_ARCH_LIST="9.0;12.0" \
    CUDA_LAUNCH_BLOCKING=0 \
    PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
WORKDIR /workspace

# ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && \
    apt-get install -y --no-install-recommends software-properties-common && \
    add-apt-repository -y ppa:deadsnakes/ppa && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
    # åŸºæœ¬ãƒ„ãƒ¼ãƒ«
    curl wget git vim nano htop tmux screen \
    build-essential cmake gcc g++ gfortran \
    ca-certificates gnupg lsb-release \
    # Python 3.11ï¼ˆPyTorch Nightlyã¨äº’æ›æ€§ãŒè‰¯ã„ï¼‰
    python3.11 python3.11-dev python3.11-venv python3-pip \
    # Node.jsç”¨ï¼ˆClaude Codeç”¨ï¼‰
    nodejs npm \
    # åŒ–å­¦è¨ˆç®—ç”¨ä¾å­˜é–¢ä¿‚
    libopenblas-dev liblapack-dev libatlas-base-dev \
    libhdf5-dev libnetcdf-dev \
    libboost-all-dev libgsl-dev \
    libfftw3-dev libsuitesparse-dev \
    # åˆ†å­æ§‹é€ å¯è¦–åŒ–ç”¨
    libgl1 libglu1-mesa \
    libxrender1 libxext6 libxi6 \
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ„ãƒ¼ãƒ«ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    iputils-ping net-tools dnsutils \
    # SSHï¼ˆå¿…è¦ãªå ´åˆï¼‰
    openssh-client \
    && rm -rf /var/lib/apt/lists/*

# Python 3.11ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«è¨­å®š
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1

# pipã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
RUN python3.11 -m pip install --upgrade pip

# ===================================================
# RTX 50ã‚·ãƒªãƒ¼ã‚ºå¯¾å¿œ: PyTorch Nightly (cu128) ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# ===================================================
RUN pip install --no-cache-dir --pre \
    torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/nightly/cu128

# CuPy for CUDA 12.xï¼ˆGPU4PySCFç”¨ï¼‰
RUN pip install --no-cache-dir \
    cupy-cuda12x==13.6.0 \
    cutensor-cu12

# åŸºæœ¬çš„ãªç§‘å­¦è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
RUN pip install --no-cache-dir \
    numpy==1.26.4 \
    scipy==1.13.0 \
    pandas==2.2.2 \
    matplotlib==3.8.4 \
    seaborn==0.13.2 \
    plotly==5.20.0 \
    jupyter==1.0.0 \
    jupyterlab==4.1.5 \
    ipython==8.23.0

# æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆPyTorchä»¥å¤–ï¼‰
RUN pip install --no-cache-dir \
    tensorflow==2.16.1 \
    scikit-learn==1.4.2 \
    xgboost==2.0.3 \
    lightgbm==4.3.0 \
    catboost==1.2.3 \
    keras==3.1.1

# Deep Learning - Transformers & Ecosystem
RUN pip install --no-cache-dir \
    transformers==4.40.0 \
    accelerate==0.29.3 \
    datasets==2.19.0 \
    tokenizers==0.19.1 \
    sentencepiece==0.2.0

# è¨ˆç®—åŒ–å­¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆGPUå¯¾å¿œç‰ˆå«ã‚€ï¼‰
RUN pip install --no-cache-dir \
    rdkit==2024.03.1 \
    ase==3.22.1 \
    mdanalysis==2.7.0 \
    mdtraj==1.10.0 \
    pyscf==2.5.0 \
    gpu4pyscf-cuda12x==1.4.2 \
    geometric==1.1 \
    pubchempy==1.0.4 \
    py3Dmol==2.5.2 \
    openbabel-wheel==3.1.1.18 \
    chempy==0.8.3

# åˆ†å­ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
RUN pip install --no-cache-dir \
    biopython==1.83 \
    biotite==0.39.0 \
    prody==2.4.1 \
    oddt==0.8 \
    deepchem==2.7.1

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ„ãƒ¼ãƒ«
RUN pip install --no-cache-dir \
    h5py==3.11.0 \
    netCDF4==1.6.5 \
    xarray==2024.3.0 \
    dask==2024.4.2 \
    bokeh==3.4.1 \
    altair==5.3.0 \
    networkx==3.3

# é–‹ç™ºãƒ„ãƒ¼ãƒ«
RUN pip install --no-cache-dir \
    joblib==1.4.0 \
    tqdm==4.66.2 \
    rich==13.7.1 \
    pytest==8.1.1 \
    black==24.3.0 \
    flake8==7.0.0 \
    mypy==1.9.0 \
    pre-commit==3.7.0 \
    uv

# Node.jsæœ€æ–°åŒ–ã¨Claude Codeé–¢é€£ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs && \
    npm install -g npm@latest

# Claude Codeã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN npm install -g @anthropic-ai/claude-code

# Claude-bridgeã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
RUN git clone https://github.com/guychenya/LLMBridgeClaudeCode.git /opt/claude-bridge && \
    cd /opt/claude-bridge && \
    uv venv && \
    . .venv/bin/activate && \
    uv pip install -r requirements.txt

# Serena-MCPã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN pip install --no-cache-dir git+https://github.com/oraios/serena.git

# Ollama-MCP-Bridgeã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
RUN git clone https://github.com/patruff/ollama-mcp-bridge.git /opt/ollama-mcp-bridge && \
    cd /opt/ollama-mcp-bridge && \
    npm install && \
    npm run build || true

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
# Claude-bridgeè¨­å®š
RUN mkdir -p /root/.claude-bridge && \
    cat <<EOF > /root/.claude-bridge/config.json
{
  "ollama": {
    "baseUrl": "http://host.docker.internal:11434",
    "model": "__OLLAMA_MODEL_PLACEHOLDER__",
    "timeout": 300000
  },
  "server": {
    "port": 8080,
    "host": "0.0.0.0"
  },
  "logging": {
    "level": "info",
    "file": "/workspace/logs/claude-bridge.log"
  }
}
EOF

# Serena-MCPè¨­å®š
RUN mkdir -p /root/.serena && \
    cat <<EOF > /root/.serena/serena_config.yml
contexts:
  agent:
    system_prompt: |
      You are Serena, a powerful coding agent specialized in computational chemistry and machine learning.
      You have access to comprehensive Python libraries for scientific computing.
    tools:
      - read_file
      - write_file
      - search_symbols
      - edit_code
      - execute_command
      - create_project
      
modes:
  research:
    description: "Research mode for computational chemistry"
    context: agent
    
settings:
  workspace_dir: /workspace
  max_file_size: 10485760
  enable_web_dashboard: true
  dashboard_port: 9122
EOF

# MCPçµ±åˆè¨­å®š
RUN mkdir -p /root/.config/claude && \
    cat <<EOF > /root/.config/claude/config.json
{
  "mcpServers": {
    "serena": {
      "command": "serena",
      "args": ["start-mcp-server", "--context", "agent", "--transport", "stdio"]
    },
    "ollama-bridge": {
      "command": "node",
      "args": ["/opt/ollama-mcp-bridge/dist/index.js"],
      "env": {
        "OLLAMA_HOST": "http://host.docker.internal:11434"
      }
    },
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/workspace"]
    }
  }
}
EOF

# GPUæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ
RUN cat <<'SCRIPT' > /usr/local/bin/verify-gpu.py
#!/usr/bin/env python3
import torch
import sys

print("=" * 60)
print("RTX 50ã‚·ãƒªãƒ¼ã‚º GPUæ¤œè¨¼")
print("=" * 60)

# CUDAåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
cuda_available = torch.cuda.is_available()
print(f"CUDAåˆ©ç”¨å¯èƒ½: {cuda_available}")

if cuda_available:
    # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
    device_count = torch.cuda.device_count()
    print(f"GPUãƒ‡ãƒã‚¤ã‚¹æ•°: {device_count}")
    
    for i in range(device_count):
        props = torch.cuda.get_device_properties(i)
        print(f"\nGPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"  Compute Capability: {props.major}.{props.minor}")
        print(f"  ãƒ¡ãƒ¢ãƒª: {props.total_memory / 1e9:.1f} GB")
        print(f"  SMæ•°: {props.multi_processor_count}")
        
        # sm_120ã®ãƒã‚§ãƒƒã‚¯
        if props.major == 12 and props.minor == 0:
            print(f"  âœ… sm_120 (Blackwell) æ¤œå‡º!")
    
    # PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    print(f"\nPyTorch Version: {torch.__version__}")
    print(f"CUDA Version: {torch.version.cuda}")
    print(f"cuDNN Version: {torch.backends.cudnn.version()}")
    
    # ç°¡å˜ãªGPUæ¼”ç®—ãƒ†ã‚¹ãƒˆ
    try:
        test_tensor = torch.randn(1000, 1000).cuda()
        result = torch.mm(test_tensor, test_tensor)
        print("\nâœ… GPUæ¼”ç®—ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
    except Exception as e:
        print(f"\nâŒ GPUæ¼”ç®—ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        sys.exit(1)
else:
    print("âŒ CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    sys.exit(1)

print("=" * 60)
SCRIPT

# GPUåˆ†å­è¨ˆç®—ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ
RUN cat <<'SCRIPT' > /usr/local/bin/test-gpu-chemistry.py
#!/usr/bin/env python3
"""
RTX 50ã‚·ãƒªãƒ¼ã‚ºã§ã®GPUåŠ é€Ÿåˆ†å­è¨ˆç®—ãƒ‡ãƒ¢
"""
import torch
import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors
import pyscf
from pyscf import gto, scf
import pubchempy as pcp

print("=" * 60)
print("GPUåŠ é€Ÿåˆ†å­è¨ˆç®—ç’°å¢ƒãƒ†ã‚¹ãƒˆ")
print("=" * 60)

# 1. GPUç¢ºèª
print("\n[1] GPUçŠ¶æ…‹ç¢ºèª")
if torch.cuda.is_available():
    print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    props = torch.cuda.get_device_properties(0)
    if props.major == 12 and props.minor == 0:
        print(f"âœ… RTX 50ã‚·ãƒªãƒ¼ã‚º (sm_120) æ¤œå‡ºï¼")
else:
    print("âŒ GPUåˆ©ç”¨ä¸å¯")

# 2. RDKitåˆ†å­å‡¦ç†
print("\n[2] RDKitåˆ†å­å‡¦ç†")
mol = Chem.MolFromSmiles('CC(=O)OC1=CC=CC=C1C(=O)O')  # ã‚¢ã‚¹ãƒ”ãƒªãƒ³
if mol:
    mw = Descriptors.MolWt(mol)
    logp = Descriptors.MolLogP(mol)
    print(f"âœ… ã‚¢ã‚¹ãƒ”ãƒªãƒ³: åˆ†å­é‡={mw:.2f}, LogP={logp:.2f}")

# 3. PySCFé‡å­åŒ–å­¦è¨ˆç®—
print("\n[3] PySCFé‡å­åŒ–å­¦è¨ˆç®—")
mol_h2o = gto.Mole()
mol_h2o.atom = '''
    O  0.0  0.0  0.0
    H  0.757  0.586  0.0
    H -0.757  0.586  0.0
'''
mol_h2o.basis = '6-31G'
mol_h2o.build()

# 4. GPUåŠ é€Ÿã®ç¢ºèªï¼ˆgpu4pyscfãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
try:
    import gpu4pyscf
    print("âœ… gpu4pyscf ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ - GPUåŠ é€Ÿåˆ©ç”¨å¯èƒ½")
    # GPUåŠ é€ŸSCFè¨ˆç®—
    mf = gpu4pyscf.scf.RHF(mol_h2o).to_gpu()
    energy = mf.kernel()
    print(f"   HF Energy (GPU): {energy:.6f} Hartree")
except ImportError:
    print("âš ï¸  gpu4pyscf CPUç‰ˆã‚’ä½¿ç”¨")
    mf = scf.RHF(mol_h2o)
    energy = mf.kernel()
    print(f"   HF Energy (CPU): {energy:.6f} Hartree")

# 5. PubChemPyãƒ†ã‚¹ãƒˆ
print("\n[4] PubChemPyãƒ‡ãƒ¼ã‚¿å–å¾—")
try:
    compounds = pcp.get_compounds('Aspirin', 'name')
    if compounds:
        c = compounds[0]
        print(f"âœ… PubChem CID: {c.cid}")
        print(f"   åˆ†å­å¼: {c.molecular_formula}")
except Exception as e:
    print(f"âš ï¸  PubChemã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")

print("\n" + "=" * 60)
print("ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
print("=" * 60)
SCRIPT

RUN chmod +x /usr/local/bin/test-gpu-chemistry.py

# èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ
RUN cat <<'SCRIPT' > /usr/local/bin/start-environment.sh
#!/bin/bash
set -e

echo "ğŸš€ RTX 50ã‚·ãƒªãƒ¼ã‚ºå¯¾å¿œ è¨ˆç®—åŒ–å­¦ãƒ»æ©Ÿæ¢°å­¦ç¿’ç ”ç©¶ç’°å¢ƒã‚’èµ·å‹•ã—ã¦ã„ã¾ã™..."

# GPUæ¤œè¨¼
echo "ğŸ® GPUæ¤œè¨¼ä¸­..."
python3 /usr/local/bin/verify-gpu.py || {
    echo "âš ï¸ GPUæ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ç¶šè¡Œã—ã¾ã™..."
}

# åˆ†å­è¨ˆç®—ç’°å¢ƒãƒ†ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
echo "ğŸ§ª åˆ†å­è¨ˆç®—ç’°å¢ƒã®ç¢ºèªä¸­..."
python3 -c "import pyscf, rdkit, pubchempy, py3Dmol; print('âœ… ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆ©ç”¨å¯èƒ½')" || {
    echo "âš ï¸ ä¸€éƒ¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
}

# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p /workspace/logs

# Ollamaã®æ¥ç¶šç¢ºèª
echo "ğŸ” Ollamaã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šã‚’ç¢ºèªä¸­..."
if curl -s http://host.docker.internal:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šæˆåŠŸ"
else
    echo "âš ï¸  è­¦å‘Š: Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒ›ã‚¹ãƒˆå´ã§OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
fi

# Claude-bridgeã®èµ·å‹•
echo "ğŸŒ‰ Claude-bridgeã‚’èµ·å‹•ä¸­..."
# ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰åæ˜ 
sed -i "s|__OLLAMA_MODEL_PLACEHOLDER__|${OLLAMA_MODEL:-gpt-oss-20b}|g" /root/.claude-bridge/config.json
cd /opt/claude-bridge
source .venv/bin/activate
python -m llm_bridge_claude_code &
BRIDGE_PID=$!
echo "âœ… Claude-bridgeèµ·å‹• (PID: $BRIDGE_PID)"

# Serena-MCPã®èµ·å‹•ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ï¼‰
echo "ğŸ¯ Serena-MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­..."
serena start-mcp-server --context agent --transport sse --port 9121 2>/dev/null &
SERENA_PID=$!
echo "âœ… Serena-MCPèµ·å‹• (PID: $SERENA_PID)"

# JupyterLabã®èµ·å‹•
echo "ğŸ“Š JupyterLabã‚’èµ·å‹•ä¸­..."
jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root \
    --NotebookApp.token="${JUPYTER_TOKEN:-research2025}" &
JUPYTER_PID=$!
echo "âœ… JupyterLabèµ·å‹• (PID: $JUPYTER_PID)"

echo ""
echo "=========================================="
echo "ğŸ‰ ç’°å¢ƒã®èµ·å‹•ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
echo "=========================================="
echo ""
echo "ğŸ“Œ ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±:"
echo "  - JupyterLab: http://localhost:8888"
echo "  - Claude-bridge: http://localhost:8080"
echo "  - Serena-MCP: http://localhost:9121"
echo "  - Serena Dashboard: http://localhost:9122"
echo ""
echo "ğŸ® RTX 50ã‚·ãƒªãƒ¼ã‚º (sm_120) ã‚µãƒãƒ¼ãƒˆæœ‰åŠ¹"
echo "ğŸ”§ CUDA 12.8 + PyTorch Nightly"
echo ""
echo "ğŸ’¡ Claude Codeã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯:"
echo "  docker exec -it comp-chem-ml-env claude"
echo ""
echo "ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /workspace"
echo ""

# ãƒ—ãƒ­ã‚»ã‚¹ã®ç›£è¦–
wait
SCRIPT

RUN chmod +x /usr/local/bin/start-environment.sh

# Pythonãƒ‘ã‚¹è¨­å®š
ENV PYTHONPATH="/workspace:$PYTHONPATH"

# ãƒãƒ¼ãƒˆå…¬é–‹
EXPOSE 8080 8888 9121 9122

# ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒã‚¦ãƒ³ãƒˆãƒã‚¤ãƒ³ãƒˆ
VOLUME ["/workspace", "/root/.claude", "/root/.serena"]

# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
ENTRYPOINT ["/usr/local/bin/start-environment.sh"]
